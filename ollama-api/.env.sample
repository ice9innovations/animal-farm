# Ollama LLM API Configuration

# Service Settings
PORT=7782
PRIVATE=true

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
TEXT_MODEL=llama2
VISION_MODEL=llava
TEMPERATURE=0.3

PROMPT=Briefly describe this image in a single short sentence.

# API Configuration (required for emoji lookup)
API_HOST=localhost
API_PORT=8080
API_TIMEOUT=2.0
